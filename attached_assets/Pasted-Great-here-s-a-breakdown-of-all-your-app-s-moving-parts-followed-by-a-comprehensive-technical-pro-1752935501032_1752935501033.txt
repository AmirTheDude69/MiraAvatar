Great — here's a breakdown of all your app's moving parts, followed by a comprehensive technical prompt with requirements, tech stack, and an outline you can use to build it on **Replit**.

---

## ✅ Functional Overview

You’re building a **web-based AI Avatar Chatbot** that:

1. **Accepts a user’s CV (PDF)**
2. **Extracts and processes the content**
3. **Stores/analyzes the content via WeAviate**
4. **Uses OpenAI to generate natural language feedback**
5. **Speaks the feedback out loud using ElevenLabs**
6. **Displays an animated avatar that "talks" to the user**

---

## 🧱 Requirements Breakdown

### 🔹 Frontend (Next.js on Replit)

* **File Upload UI** (PDF only)
* **Display area** for avatar + audio playback
* **Loading states + error handling**
* **Chatbot dialogue UI** (optional: chat bubble view)

### 🔹 Backend (Python + Node hybrid)

You’ll need a **backend server in Python**, and **possibly a Node.js layer** for front-facing API integration.

#### Core Modules:

* **PDF Parsing**: `pypdf`
* **OpenAI API** (e.g., GPT-4)
* **WeAviate API** for storage/processing
* **ElevenLabs API** for text-to-speech
* **Socket or API endpoint for avatar response control**

### 🔹 External APIs

* **ElevenLabs API**: Text-to-speech audio generation
* **OpenAI API**: CV analysis and feedback generation
* **WeAviate API**: Storing and querying parsed CV data

---

## 🧰 Full Tech Stack

### Languages:

* **Frontend**: JavaScript, React (Next.js)
* **Backend**: Python 3.11+, Node.js (optional proxy layer)
* **Styling**: TailwindCSS or CSS Modules

### Libraries & Tools:

| Purpose                 | Tech                             |
| ----------------------- | -------------------------------- |
| Web Framework           | Next.js                          |
| Styling                 | TailwindCSS                      |
| File Upload             | `react-dropzone` / HTML5 Input   |
| PDF Parsing             | `pypdf` (Python)                 |
| NLP                     | OpenAI API (ChatCompletion)      |
| Storage                 | WeAviate API                     |
| Voice Output            | ElevenLabs API                   |
| Avatar Animation        | Three.js / prebuilt WebGL avatar |
| API Handling (Frontend) | Axios / native fetch             |
| Replit DB (optional)    | For small user session caching   |

---

## ⚙️ System Architecture (Simplified)

```plaintext
[User Uploads CV]
      ↓
[Frontend UI - Next.js]
      ↓
[API Route /backend/process_cv] → (Python server)
      ↓
[Extract Text via pypdf]
      ↓
[Send to WeAviate API → Store/Process]
      ↓
[Pass Text to OpenAI API → Feedback Generated]
      ↓
[Send Feedback to ElevenLabs → Get Audio File]
      ↓
[Frontend Avatar Component + Audio Playback]
```

---

## 📦 Replit Workspace Setup

To make this Replit project run smoothly, your workspace should be structured like this:

```bash
/my-app
├── frontend/                  # Next.js frontend
│   ├── pages/
│   ├── components/            # Avatar UI, upload form, etc.
│   └── ...
├── backend/                   # Python backend
│   ├── main.py                # Flask or FastAPI server
│   ├── pdf_parser.py
│   ├── openai_integration.py
│   ├── elevenlabs_integration.py
│   └── weaviate_client.py
├── replit.nix                 # Define runtime environments (Node + Python)
```

> ⚠️ Replit doesn’t natively support monorepos well, so you may need to either use Replit's \[Bash/console-based setup] or separate it into two Replit projects and connect via HTTP.

---

## 🧠 Detailed Prompt to Start Building

Here’s a comprehensive prompt you can use inside Replit or when working with a dev assistant or codegen agent:

---

**Prompt:**

> Build a full-stack web app using **Next.js (frontend)** and **Python (backend)** where users can upload their CV (PDF). The app should:
>
> 1. Use `pypdf` to extract text from the uploaded PDF.
> 2. Send the text to the **WeAviate API** to store and process the CV.
> 3. Use **OpenAI's ChatCompletion API (GPT-4)** to generate detailed natural-language feedback on the CV.
> 4. Convert the generated feedback to audio using the **ElevenLabs API**.
> 5. Display an animated avatar that appears to "speak" the feedback out loud.
>
> ### Features:
>
> * PDF upload via web UI (Next.js)
> * REST API to trigger PDF parsing, LLM generation, and voice synthesis
> * Display feedback text + avatar + voice playback
> * Responsive design, with progress/loading indicators
>
> ### Tech stack:
>
> * Frontend: Next.js, TailwindCSS, Axios
> * Backend: Python (Flask or FastAPI)
> * Audio: ElevenLabs API
> * NLP: OpenAI API
> * PDF Parsing: pypdf
> * Storage/Indexing: WeAviate API
> * Avatar: WebGL (Three.js) or Lottie animation

---

Would you like me to generate the **starter code template** for this (backend + frontend structure)?
